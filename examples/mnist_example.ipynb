{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa0f51-9946-4c79-8aa1-142d1f7a0e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Using random seed: {random.seed(42)}\")  # For reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c67c1f1-2b3c-4b42-bef7-5cbf292b7fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Input\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca2a5db-4a69-4d12-9114-9b40b420b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading MNIST dataset...\")\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"Dataset loaded! Here's what we have:\")\n",
    "print(f\"Training images: {X_train.shape}\")\n",
    "print(f\"Training labels: {y_train.shape}\")\n",
    "print(f\"Test images: {X_test.shape}\")\n",
    "print(f\"Test labels: {y_test.shape}\")\n",
    "print(f\"Image dimensions: {X_train[0].shape} (28x28 pixels)\")\n",
    "print(f\"Pixel value range: {X_train.min()} to {X_train.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55378af-d428-499e-9721-d6251a3d052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Let's look at some handwritten digits:\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    # Use fixed indices for consistency across runs\n",
    "    idx = i * 1000  # This gives us a variety while being reproducible\n",
    "    plt.imshow(X_train[idx], cmap='gray', interpolation='none')\n",
    "    plt.title(f\"Label: {y_train[idx]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_digits.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Sample digits saved as 'sample_digits.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7189a737-8e8c-4cf7-99e9-c91d862450ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preprocessing the data...\")\n",
    "print(\"Original shape:\", X_train.shape)\n",
    "\n",
    "# Flatten the 28x28 images into 784-element vectors\n",
    "X_train_flat = X_train.reshape(60000, 784)  # 28*28 = 784\n",
    "X_test_flat = X_test.reshape(10000, 784)\n",
    "\n",
    "# Normalize pixel values to 0-1 range (neural networks work better with small numbers)\n",
    "X_train_norm = X_train_flat.astype('float32') / 255.0\n",
    "X_test_norm = X_test_flat.astype('float32') / 255.0\n",
    "\n",
    "print(\"After preprocessing:\")\n",
    "print(f\"Training data shape: {X_train_norm.shape}\")\n",
    "print(f\"Test data shape: {X_test_norm.shape}\")\n",
    "print(f\"New pixel value range: {X_train_norm.min():.1f} to {X_train_norm.max():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280395a-2a2b-4094-a475-6b9467942260",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Converting labels to one-hot encoding...\")\n",
    "print(f\"Original label example: {y_train[0]} (just a number)\")\n",
    "\n",
    "num_classes = 10  # digits 0-9\n",
    "Y_train = to_categorical(y_train, num_classes)\n",
    "Y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "print(f\"One-hot encoded example: {Y_train[0]} (array with 1 in position {y_train[0]})\")\n",
    "print(f\"Training labels shape: {Y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417234f8-a967-4218-bb19-dbe18b3f6428",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building the neural network...\")\n",
    "model = Sequential([\n",
    "    Input(shape=(784,)),           # Input layer: expects 784 features (28x28 flattened)\n",
    "    Dense(512, activation='relu'), # Hidden layer 1: 512 neurons with ReLU activation\n",
    "    Dropout(0.2),                  # Dropout: randomly ignore 20% of neurons (prevents overfitting)\n",
    "    Dense(512, activation='relu'), # Hidden layer 2: another 512 neurons\n",
    "    Dropout(0.2),                  # More dropout for regularization\n",
    "    Dense(10, activation='softmax') # Output layer: 10 neurons (one per digit), softmax gives probabilities\n",
    "])\n",
    "\n",
    "print(\"Model architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7116d0d0-895b-48ff-9c09-ace128df964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Configuring the model for training...\")\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',  # Good for multi-class classification\n",
    "    optimizer='adam',                 # Adaptive learning rate optimizer\n",
    "    metrics=['accuracy']              # Track accuracy during training\n",
    ")\n",
    "print(\"Model compiled and ready to train!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438f2014-25e9-4940-9550-e29bb7f4c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "print(\"This should be fairly fast with our resources...\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_norm, Y_train,\n",
    "    batch_size=128,    # Process 128 examples at a time\n",
    "    epochs=10,         # Go through entire dataset 10 times\n",
    "    verbose=1,         # Show progress\n",
    "    validation_split=0.1  # Use 10% of training data for validation\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926df8ef-d81e-4a45-b81b-d7c62a8a4f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating model performance...\")\n",
    "test_loss, test_accuracy = model.evaluate(X_test_norm, Y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9977cf1e-9956-406c-be06-36fd678d2193",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Visualize the training progress\")\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Training history saved as 'training_history.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fa24bb-c3e0-4689-9e1a-1b15b13f6bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Making predictions on test examples...\")\n",
    "predictions = model.predict(X_test_norm[:10])  # Predict first 10 test examples\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(X_test[i], cmap='gray')\n",
    "    predicted_digit = np.argmax(predictions[i])\n",
    "    actual_digit = y_test[i]\n",
    "    confidence = predictions[i][predicted_digit]\n",
    "    \n",
    "    color = 'green' if predicted_digit == actual_digit else 'red'\n",
    "    plt.title(f'Pred: {predicted_digit} (Actual: {actual_digit})\\nConfidence: {confidence:.3f}', \n",
    "              color=color)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('predictions_sample.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Prediction examples saved as 'predictions_sample.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc82714a-b3ad-4d26-be73-ecfa23fb3c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'mnist_model.h5'\n",
    "print(f\"Saving trained model in old format as '{model_filename}'...\")\n",
    "model.save(model_filename)\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Also save in newer format\n",
    "model_filename_new = 'mnist_model.keras'\n",
    "model.save(model_filename_new)\n",
    "print(f\"Model also saved in newer format as '{model_filename_new}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4517cbc-5218-4822-b87f-bb6897b7b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Demonstrating how to load a saved model...\")\n",
    "loaded_model = load_model(model_filename_new)\n",
    "# loaded_model = load_model(model_filename) #The new name (.keras) and old (.h5) should be the same so you can load either\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Verify it works the same\n",
    "test_prediction_original = model.predict(X_test_norm[:1])\n",
    "test_prediction_loaded = loaded_model.predict(X_test_norm[:1])\n",
    "print(f\"Original model prediction: {np.argmax(test_prediction_original)}\")\n",
    "print(f\"Loaded model prediction: {np.argmax(test_prediction_loaded)}\")\n",
    "print(\"✓ Both models give the same result!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TUTORIAL COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(\"What you've learned:\")\n",
    "print(\"• How to load and preprocess image data\")\n",
    "print(\"• How to build a neural network with Keras\")\n",
    "print(\"• How to train a model and track its progress\")\n",
    "print(\"• How to evaluate model performance\")\n",
    "print(\"• How to save and load trained models\")\n",
    "print(\"• How to make predictions on new data\")\n",
    "print(f\"Final test accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28f49d8-df29-4095-b8b0-93d5d3a47ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
